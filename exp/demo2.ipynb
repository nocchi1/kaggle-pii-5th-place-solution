{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../config/exp_118_train.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../config/exp_118_train.yaml\n",
    "exp: \"118\"\n",
    "first_exp: \"087\"\n",
    "run_type: \"train\"\n",
    "task_type: \"classify\"\n",
    "device: \"cuda\"\n",
    "seed: 10\n",
    "\n",
    "# data preprocess\n",
    "first_negative_th: 0.400  # [TODO]あとで調整\n",
    "n_fold: 3\n",
    "use_fold: 3\n",
    "\n",
    "# dataset, dataloader\n",
    "add_newline_token: true\n",
    "max_length: 2048\n",
    "train_stride: 1024\n",
    "eval_stride: 1024\n",
    "train_batch: 2\n",
    "eval_batch: 4\n",
    "\n",
    "# model\n",
    "model_path: \"microsoft/deberta-v3-large\"\n",
    "class_num: 1\n",
    "lstm_type: \"none\"\n",
    "use_hidden_states: 2\n",
    "dropout: 0.10\n",
    "hidden_dropout: 0.10\n",
    "attention_dropout: 0.10\n",
    "reinit_layer_num: 0\n",
    "freeze_layer_num: 0\n",
    "\n",
    "# loss\n",
    "positive_class_weight: 10\n",
    "\n",
    "# optimizer\n",
    "optimizer_type: \"AdamW\"\n",
    "pretrained_lr: 1e-6\n",
    "head_lr: 1e-4\n",
    "weight_decay: 0.01\n",
    "betas: [0.9, 0.999]\n",
    "\n",
    "# scheduler\n",
    "scheduler_type: \"cosine_custom\"\n",
    "first_cycle_epochs: 4\n",
    "cycle_factor: 1\n",
    "num_warmup_steps: 0\n",
    "min_lr: 1e-9\n",
    "gamma: 1.0\n",
    "\n",
    "# training\n",
    "epochs: 4\n",
    "accumulation_steps: 8\n",
    "eval_steps: 1000\n",
    "# negative_th: 0.660\n",
    "# negative_th_method: \"overall\"\n",
    "amp: true\n",
    "ema: true\n",
    "ema_decay: 0.999\n",
    "ema_update_after_step: 8000\n",
    "\n",
    "# full training\n",
    "full_train: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.postprocess import PostProcessor\n",
    "from src.preprocess import ClassifyDataReader\n",
    "from src.train import Trainer, get_full_train_loader, get_train_loaders\n",
    "from src.train.dataloader_utils import CollateFn, get_sampler, get_tokenizer\n",
    "from src.utils import TimeUtil, get_config, get_logger, seed_everything\n",
    "from src.utils.metric import get_best_negative_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd-stageの目的は, 1st-stageでのNAME-STUDENTのFPを現象させること\n",
    "# 後処理は2nd-stageの前では行わずに, 2nd-stageの後で行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]コマンドライン引数\n",
    "config_name = \"exp_118_train\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-22 05:49:45\u001b[0m | \u001b[1mINFO ] exp:118 start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(config_name, config_dir=Path(\"../config\"))\n",
    "config.debug = debug\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f\"exp:{config.exp} start\")\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.input_path = Path(\"../data/input\")\n",
    "config.exter_path = Path(\"../data/input/external\")\n",
    "config.output_path = Path(\"../data/output\") / config.exp\n",
    "config.output_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ClassifyDataReader(config, \"train\")\n",
    "data = reader.load_data(first_exp=config.first_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_train_loaders(config, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df : [document, token_idx, binary_pred, name_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_first_pred_df' from 'src.utils.competition_utils' (/root/kaggle-pii-5th-place-solution/exp/../src/utils/competition_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComponentFactory\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelEmaV3\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompetition_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_char2org_df, get_char_pred_df, get_pred_df, restore_prefix, get_truth_df, get_first_pred_df\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_best_negative_threshold\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AverageMeter, clean_message\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_first_pred_df' from 'src.utils.competition_utils' (/root/kaggle-pii-5th-place-solution/exp/../src/utils/competition_utils.py)"
     ]
    }
   ],
   "source": [
    "import loguru\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "\n",
    "from src.train.component_factory import ComponentFactory\n",
    "from src.train.ema import ModelEmaV3\n",
    "from src.utils.competition_utils import (\n",
    "    get_char2org_df,\n",
    "    get_char_pred_df,\n",
    "    get_first_pred_df,\n",
    "    get_pred_df,\n",
    "    get_truth_df,\n",
    "    restore_prefix,\n",
    ")\n",
    "from src.utils.utils import AverageMeter, clean_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config: DictConfig, logger: loguru._Logger, save_suffix: str = \"\"):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.save_suffix = save_suffix\n",
    "        self.detail_pbar = True\n",
    "\n",
    "        self.model = ComponentFactory.get_model(config)\n",
    "        self.model = self.model.to(config.device)\n",
    "\n",
    "        if self.config.ema:\n",
    "            self.model_ema = ModelEmaV3(\n",
    "                self.model,\n",
    "                decay=config.ema_decay,\n",
    "                update_after_step=config.ema_update_after_step,\n",
    "                device=config.device,\n",
    "            )\n",
    "\n",
    "        self.loss_fn = ComponentFactory.get_loss(config)\n",
    "        self.train_loss = AverageMeter()\n",
    "        self.valid_loss = AverageMeter()\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        self.grad_scaler = amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "        self.truth_df = None\n",
    "        self.first_pred_df = None\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader: DataLoader,\n",
    "        valid_loader: DataLoader | None,\n",
    "        retrain: bool = False,\n",
    "        retrain_weight_name: str = \"\",\n",
    "        retrain_best_score: float = -np.inf,\n",
    "        full_train: bool = False,\n",
    "        full_steps: int = 0,\n",
    "        eval_only: bool = False,\n",
    "    ):\n",
    "        if eval_only:\n",
    "            assert not full_train, \"eval_only and full_train cannot be True at the same time\"\n",
    "            score, loss, oof_df = self.valid_evaluate(valid_loader, epoch=-1, load_best_weight=True)\n",
    "            return score, -1, oof_df\n",
    "\n",
    "        self.optimizer = ComponentFactory.get_optimizer(self.config, self.model)\n",
    "\n",
    "        global_steps = 0\n",
    "        update_steps = 0\n",
    "        best_score = -np.inf\n",
    "        best_steps = 0\n",
    "        best_oof = None\n",
    "        full_train_complete = False\n",
    "\n",
    "        if retrain:\n",
    "            self.model.load_state_dict(torch.load(self.config.output_path / f\"{retrain_weight_name}.pth\"))\n",
    "            self.model_ema.update_after_step = 0\n",
    "            best_score = retrain_best_score\n",
    "\n",
    "        # 学習ループの開始\n",
    "        epochs = self.config.epochs if not retrain else self.config.add_epochs\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            if full_train_complete:\n",
    "                break\n",
    "\n",
    "            self.model.train()\n",
    "            self.train_loss.reset()\n",
    "\n",
    "            # 1epoch目はbackboneをfreezeする\n",
    "            if epoch == 0 and not retrain:\n",
    "                self.model.freeze_backbone(self.config.reinit_layer_num)\n",
    "            elif epoch == 1 and not retrain:\n",
    "                self.model.unfreeze_backbone(self.config.freeze_layer_num)\n",
    "\n",
    "            iterations = tqdm(train_loader, total=len(train_loader)) if self.detail_pbar else train_loader\n",
    "            for data in iterations:\n",
    "                if full_train_complete:  # ループの上部でbreakする必要がある\n",
    "                    break\n",
    "\n",
    "                _, loss = self.forward_step(self.model, data)\n",
    "                self.train_loss.update(loss.item(), n=data[0].size(0))\n",
    "                loss = loss / self.config.accumulation_steps\n",
    "                self.grad_scaler.scale(loss).backward()\n",
    "                global_steps += 1\n",
    "\n",
    "                if global_steps % self.config.accumulation_steps == 0:\n",
    "                    self.grad_scaler.step(self.optimizer)\n",
    "                    self.grad_scaler.update()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    update_steps += 1\n",
    "\n",
    "                    if self.config.ema:\n",
    "                        self.model_ema.update(self.model, update_steps)\n",
    "\n",
    "                    # backboneの学習が始まってからschedulerを適用\n",
    "                    if epoch >= 1 or retrain:\n",
    "                        if self.scheduler is None:\n",
    "                            first_cycle_epochs = (\n",
    "                                self.config.first_cycle_epochs if not retrain else self.config.add_first_cycle_epochs\n",
    "                            )\n",
    "                            total_steps = first_cycle_epochs * len(train_loader)\n",
    "                            if not retrain:\n",
    "                                total_steps -= len(train_loader)  # 最初の1epoch分はstepしないから\n",
    "                            self.scheduler = ComponentFactory.get_scheduler(\n",
    "                                self.config, self.optimizer, total_steps=total_steps\n",
    "                            )\n",
    "                        self.scheduler.step()\n",
    "\n",
    "                # if global_steps % self.config.eval_steps == 0 and not full_train:\n",
    "                #     score, loss, oof_df = self.valid_evaluate(valid_loader, epoch, load_best_weight=False)\n",
    "                #     if score > best_score:\n",
    "                #         best_score = score\n",
    "                #         best_steps = global_steps\n",
    "                #         best_oof = oof_df\n",
    "                #         parameters = self.model_ema.module.state_dict() if self.config.ema else self.model.state_dict()\n",
    "                #         torch.save(\n",
    "                #             parameters,\n",
    "                #             self.config.output_path / f\"model{self.save_suffix}_best.pth\",\n",
    "                #         )\n",
    "                #     self.model.train()\n",
    "\n",
    "                # if full_train and global_steps == full_steps:\n",
    "                #     parameters = self.model_ema.module.state_dict() if self.config.ema else self.model.state_dict()\n",
    "                #     torch.save(\n",
    "                #         parameters,\n",
    "                #         self.config.output_path / f\"model{self.save_suffix}_full.pth\",\n",
    "                #     )\n",
    "                #     full_train_complete = True  # ここでbreakすると何故かnotebook kernelが落ちる現象が発生する\n",
    "\n",
    "            message = f\"\"\"\n",
    "                [Train] :\n",
    "                    Epoch={epoch},\n",
    "                    Loss={self.train_loss.avg:.5f},\n",
    "                    LR={self.optimizer.param_groups[0][\"lr\"]:.5e}\n",
    "            \"\"\"\n",
    "            self.logger.info(clean_message(message))\n",
    "\n",
    "            # if self.config.smooth_type == \"online\":\n",
    "            #     self.loss_fn.update_soft_matrix()\n",
    "\n",
    "        return best_score, best_steps, best_oof\n",
    "\n",
    "    def valid_evaluate(self, valid_loader: DataLoader, epoch: int, load_best_weight: bool = False):\n",
    "        if load_best_weight:\n",
    "            self.model.load_state_dict(torch.load(self.config.output_path / f\"model{self.save_suffix}_best.pth\"))\n",
    "\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            iterations = tqdm(valid_loader, total=len(valid_loader)) if self.detail_pbar else valid_loader\n",
    "            for data in iterations:\n",
    "                if load_best_weight or not self.config.ema:\n",
    "                    out, loss = self.forward_step(self.model, data)\n",
    "                else:\n",
    "                    out, loss = self.forward_step(self.model_ema, data)\n",
    "\n",
    "                self.valid_loss.update(loss.item(), n=data[0].size(0))\n",
    "                if self.config.task_type == \"detect\":\n",
    "                    preds.extend(F.softmax(out, dim=-1).cpu().numpy().tolist())\n",
    "                elif self.config.task_type == \"classify\":\n",
    "                    preds.extend(F.sigmoid(out).cpu().numpy().tolist())\n",
    "\n",
    "        oof_df = self.get_oof_df(preds, valid_loader)\n",
    "\n",
    "        if self.truth_df is None:\n",
    "            self.truth_df = get_truth_df(self.config, oof_df[\"document\"].unique().to_list(), convert_idx=True)\n",
    "\n",
    "        if self.first_pred_df is None:\n",
    "            self.first_pred_df = get_first_pred_df(\n",
    "                self.config,\n",
    "                oof_file_path=self.config.output_path.parent / self.config.first_exp / \"oof.parquet\",\n",
    "                document_ids=oof_df[\"document\"].unique().to_list(),\n",
    "                negative_th=self.config.first_negative_th,\n",
    "            )\n",
    "\n",
    "        if self.task_type == \"detect\":\n",
    "            score, best_th = get_best_negative_threshold(self.config, oof_df, self.truth_df)\n",
    "        elif self.task_type == \"classify\":\n",
    "            score, best_th = None  # [TODO]\n",
    "\n",
    "        loss = self.valid_loss.avg\n",
    "        message = f\"\"\"\n",
    "            Valid :\n",
    "                Epoch={epoch},\n",
    "                Loss={loss:.5f},\n",
    "                Score={score:.5f}\n",
    "                Threshold={best_th}\n",
    "        \"\"\"\n",
    "        self.logger.info(clean_message(message))\n",
    "        return score, loss, oof_df\n",
    "\n",
    "        #     self.first_pred_df = first_pred_df\n",
    "\n",
    "        # pred_df = self.first_pred_df.join(oof_df, on=[\"document\", \"token_idx\"], how=\"left\", coalesce=True)\n",
    "        # pass\n",
    "        # return score, best_th\n",
    "\n",
    "    def forward_step(self, model: nn.Module, data: torch.Tensor):\n",
    "        if self.config.task_type == \"detect\":\n",
    "            input_ids, attention_mask, positions_feats, labels = data\n",
    "            positions_feats = positions_feats.to(self.config.device)\n",
    "        elif self.config.task_type == \"classify\":\n",
    "            input_ids, attention_mask, labels = data\n",
    "\n",
    "        input_ids = input_ids.to(self.config.device)\n",
    "        attention_mask = attention_mask.to(self.config.device)\n",
    "        labels = labels.to(self.config.device)\n",
    "\n",
    "        with amp.autocast(enabled=self.config.amp):\n",
    "            if self.config.task_type == \"detect\":\n",
    "                out = model(input_ids, attention_mask, positions_feats)\n",
    "            elif self.config.task_type == \"classify\":\n",
    "                out = model(input_ids, attention_mask)\n",
    "            loss = self.loss_fn(out, labels)\n",
    "        return out, loss\n",
    "\n",
    "    def get_oof_df(self, preds: list[list[float]], valid_loader: DataLoader):\n",
    "        char_pred_df = get_char_pred_df(\n",
    "            preds,\n",
    "            valid_loader.dataset.overlap_doc_ids,\n",
    "            valid_loader.dataset.offset_mapping,\n",
    "            class_num=self.config.class_num,\n",
    "        )\n",
    "        char2org_df = get_char2org_df(\n",
    "            valid_loader.dataset.doc_ids,\n",
    "            valid_loader.dataset.full_texts,\n",
    "            valid_loader.dataset.org_tokens,\n",
    "            valid_loader.dataset.whitespaces,\n",
    "        )\n",
    "        oof_df = char2org_df.join(char_pred_df, on=[\"document\", \"char_idx\"], how=\"left\", coalesce=True)\n",
    "        oof_df = (\n",
    "            oof_df.filter(pl.col(\"token_idx\") != -1)\n",
    "            .group_by(\"document\", \"token_idx\")\n",
    "            .agg([pl.col(f\"pred_{i}\").mean() for i in range(self.config.class_num)])\n",
    "        )\n",
    "        return oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1811f536b3f0418596bc8411b423c8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_loader = dataloaders[0][1]\n",
    "model = ComponentFactory.get_model(config)\n",
    "loss_fn = ComponentFactory.get_loss(config)\n",
    "model = model.to(config.device)\n",
    "\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    iterations = tqdm(valid_loader, total=len(valid_loader))\n",
    "    for data in iterations:\n",
    "        input_ids, attention_mask, labels = data\n",
    "        input_ids = input_ids.to(config.device)\n",
    "        attention_mask = attention_mask.to(config.device)\n",
    "        labels = labels.to(config.device)\n",
    "\n",
    "        with amp.autocast(enabled=config.amp):\n",
    "            out = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(out, labels)\n",
    "        preds.extend(F.sigmoid(out).cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_num = 1\n",
    "\n",
    "char_pred_df = get_char_pred_df(\n",
    "    preds,\n",
    "    valid_loader.dataset.overlap_doc_ids,\n",
    "    valid_loader.dataset.offset_mapping,\n",
    "    class_num=config.class_num,\n",
    ")\n",
    "char2org_df = get_char2org_df(\n",
    "    valid_loader.dataset.doc_ids,\n",
    "    valid_loader.dataset.full_texts,\n",
    "    valid_loader.dataset.org_tokens,\n",
    "    valid_loader.dataset.whitespaces,\n",
    ")\n",
    "oof_df = char2org_df.join(char_pred_df, on=[\"document\", \"char_idx\"], how=\"left\", coalesce=True)\n",
    "oof_df = (\n",
    "    oof_df.filter(pl.col(\"token_idx\") != -1)\n",
    "    .group_by(\"document\", \"token_idx\")\n",
    "    .agg([pl.col(f\"pred_{i}\").mean() for i in range(config.class_num)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = get_truth_df(config, oof_df[\"document\"].unique().to_list(), convert_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (25_222, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>token_idx</th><th>pred_0</th><th>pred_1</th><th>pred_2</th><th>pred_3</th><th>pred_4</th><th>pred_5</th><th>pred_6</th><th>pred_7</th></tr><tr><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1210</td><td>153</td><td>0.646484</td><td>0.082275</td><td>0.04895</td><td>0.042053</td><td>0.046341</td><td>0.037064</td><td>0.046234</td><td>0.050644</td></tr><tr><td>2058</td><td>857</td><td>0.711182</td><td>0.056061</td><td>0.037735</td><td>0.035416</td><td>0.039917</td><td>0.031471</td><td>0.042725</td><td>0.045547</td></tr><tr><td>1325</td><td>110</td><td>0.692627</td><td>0.041061</td><td>0.049194</td><td>0.038605</td><td>0.047852</td><td>0.03714</td><td>0.048416</td><td>0.045334</td></tr><tr><td>2058</td><td>75</td><td>0.698975</td><td>0.050385</td><td>0.046539</td><td>0.029518</td><td>0.036362</td><td>0.039703</td><td>0.042831</td><td>0.055679</td></tr><tr><td>166</td><td>92</td><td>0.715332</td><td>0.052261</td><td>0.043762</td><td>0.031235</td><td>0.038345</td><td>0.03476</td><td>0.048981</td><td>0.035248</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2745</td><td>548</td><td>0.689697</td><td>0.035629</td><td>0.033188</td><td>0.037094</td><td>0.035004</td><td>0.035995</td><td>0.091553</td><td>0.041748</td></tr><tr><td>1185</td><td>398</td><td>0.736084</td><td>0.0383</td><td>0.029083</td><td>0.03653</td><td>0.036774</td><td>0.034592</td><td>0.045471</td><td>0.043182</td></tr><tr><td>2722</td><td>859</td><td>0.722656</td><td>0.040604</td><td>0.034805</td><td>0.036758</td><td>0.036713</td><td>0.035248</td><td>0.056259</td><td>0.036911</td></tr><tr><td>1814</td><td>228</td><td>0.71582</td><td>0.038513</td><td>0.029724</td><td>0.03952</td><td>0.034882</td><td>0.036697</td><td>0.054214</td><td>0.05069</td></tr><tr><td>2722</td><td>103</td><td>0.712891</td><td>0.044174</td><td>0.032227</td><td>0.035873</td><td>0.04155</td><td>0.037704</td><td>0.05426</td><td>0.041229</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (25_222, 10)\n",
       "┌──────────┬───────────┬──────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
       "│ document ┆ token_idx ┆ pred_0   ┆ pred_1   ┆ … ┆ pred_4   ┆ pred_5   ┆ pred_6   ┆ pred_7   │\n",
       "│ ---      ┆ ---       ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ i32      ┆ i32       ┆ f64      ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞══════════╪═══════════╪══════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
       "│ 1210     ┆ 153       ┆ 0.646484 ┆ 0.082275 ┆ … ┆ 0.046341 ┆ 0.037064 ┆ 0.046234 ┆ 0.050644 │\n",
       "│ 2058     ┆ 857       ┆ 0.711182 ┆ 0.056061 ┆ … ┆ 0.039917 ┆ 0.031471 ┆ 0.042725 ┆ 0.045547 │\n",
       "│ 1325     ┆ 110       ┆ 0.692627 ┆ 0.041061 ┆ … ┆ 0.047852 ┆ 0.03714  ┆ 0.048416 ┆ 0.045334 │\n",
       "│ 2058     ┆ 75        ┆ 0.698975 ┆ 0.050385 ┆ … ┆ 0.036362 ┆ 0.039703 ┆ 0.042831 ┆ 0.055679 │\n",
       "│ 166      ┆ 92        ┆ 0.715332 ┆ 0.052261 ┆ … ┆ 0.038345 ┆ 0.03476  ┆ 0.048981 ┆ 0.035248 │\n",
       "│ …        ┆ …         ┆ …        ┆ …        ┆ … ┆ …        ┆ …        ┆ …        ┆ …        │\n",
       "│ 2745     ┆ 548       ┆ 0.689697 ┆ 0.035629 ┆ … ┆ 0.035004 ┆ 0.035995 ┆ 0.091553 ┆ 0.041748 │\n",
       "│ 1185     ┆ 398       ┆ 0.736084 ┆ 0.0383   ┆ … ┆ 0.036774 ┆ 0.034592 ┆ 0.045471 ┆ 0.043182 │\n",
       "│ 2722     ┆ 859       ┆ 0.722656 ┆ 0.040604 ┆ … ┆ 0.036713 ┆ 0.035248 ┆ 0.056259 ┆ 0.036911 │\n",
       "│ 1814     ┆ 228       ┆ 0.71582  ┆ 0.038513 ┆ … ┆ 0.034882 ┆ 0.036697 ┆ 0.054214 ┆ 0.05069  │\n",
       "│ 2722     ┆ 103       ┆ 0.712891 ┆ 0.044174 ┆ … ┆ 0.04155  ┆ 0.037704 ┆ 0.05426  ┆ 0.041229 │\n",
       "└──────────┴───────────┴──────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pred_df = pl.read_parquet(config.output_path.parent / config.first_exp / \"oof.parquet\")\n",
    "first_pred_df = first_pred_df.filter(pl.col(\"document\").is_in(oof_df[\"document\"].unique()))\n",
    "class_num = len(list(filter(lambda x: \"pred\" in x, first_pred_df.columns)))\n",
    "first_pred_df = get_pred_df(first_pred_df, class_num=class_num, negative_th=config.first_negative_th)\n",
    "if class_num == 8:\n",
    "    first_pred_df = restore_prefix(config, first_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = first_pred_df.join(\n",
    "    oof_df.rename({\"pred_0\": \"name_pred\"}), on=[\"document\", \"token_idx\"], how=\"left\", coalesce=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metric import evaluate_metric\n",
    "\n",
    "\n",
    "def get_best_name_pred_threshold(\n",
    "    config: DictConfig, pred_df: pl.DataFrame, truth_df: pl.DataFrame, stride: float = 0.025\n",
    "):\n",
    "    \"\"\"\n",
    "    2nd-stage(classification)における閾値を探索する関数\n",
    "    args:\n",
    "        pred_df(pl.DataFrame): [document, token_idx, detect_prob, detect_pred, name_pred]\n",
    "    \"\"\"\n",
    "    best_score = evaluate_metric(pred_df, truth_df)\n",
    "    best_th = None\n",
    "\n",
    "    pred_df = pred_df.with_columns(org_pred=pl.col(\"pred\"))\n",
    "    min_th, max_th = 0.10, 0.90\n",
    "    for th in np.arange(min_th, max_th, stride):\n",
    "        pred_df = pred_df.with_columns(\n",
    "            pred=pl.when((pl.col(\"org_pred\").is_in([1, 8])) & (pl.col(\"name_pred\") < th))\n",
    "            .then(0)\n",
    "            .otherwise(pl.col(\"pred\"))\n",
    "        )\n",
    "        score = evaluate_metric(pred_df, truth_df)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_th = th\n",
    "    return best_score, best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_th = get_best_name_pred_threshold(config, pred_df, truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0911214953271028, None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_dfs = []\n",
    "best_steps, best_add_steps = [], []\n",
    "collate_fn = CollateFn(get_tokenizer(config), is_train=True)\n",
    "\n",
    "# この学習でベストなステップ数とOOFに対する予測値を取ることが目的\n",
    "for fold, (train_loader, valid_loader) in enumerate(dataloaders):\n",
    "    logger.info(f\"FOLD{fold} : Training Start...\")\n",
    "\n",
    "    # First Training\n",
    "    trainer = Trainer(config, logger, save_suffix=f\"_fold{fold}\")\n",
    "    best_score, best_steps_, oof_df = trainer.train(train_loader, valid_loader)\n",
    "    if config.smooth_type == \"online\":\n",
    "        loss_soft_matrix = trainer.loss_fn.soft_matrix.clone()\n",
    "    best_steps.append(best_steps_)\n",
    "    logger.info(f\"FOLD{fold} : First Training Done! -->> Best Score: {best_score}, Best Steps: {best_steps_}\")\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    oof_df.write_parquet(config.output_path / f\"oof_fold{fold}.parquet\")\n",
    "    oof_dfs.append(oof_df)\n",
    "    logger.info(\n",
    "        f\"FOLD{fold} : Additional Training Done! -->> Best Score: {best_score}, Best Add Steps: {best_add_steps_}\"\n",
    "    )\n",
    "\n",
    "    del train_loader, valid_loader, train_dataset, trainer, oof_df\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "del dataloaders\n",
    "gc.collect()\n",
    "\n",
    "# Save OOF\n",
    "oof_df = pl.concat(oof_dfs)\n",
    "oof_df.write_parquet(config.output_path / \"oof.parquet\")\n",
    "del oof_dfs\n",
    "gc.collect()\n",
    "\n",
    "# Get Best Negative Threshold\n",
    "best_score, best_th = get_best_negative_threshold(config, oof_df)\n",
    "message = f\"Overall OOF Best Score: {best_score}, Best Negative Threshold: {best_th}\"\n",
    "logger.info(message)\n",
    "config.negative_th = best_th.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    input_ids, attention_mask, labels = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 914]), torch.Size([2, 914]), torch.Size([2, 914]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size(), attention_mask.size(), labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    import torch\n",
    "\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "\n",
    "class DetectModel(nn.Module):\n",
    "    def __init__(self, config: DictConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.use_hidden_states = config.use_hidden_states\n",
    "        self.model_config = AutoConfig.from_pretrained(config.model_path)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": config.hidden_dropout,\n",
    "                \"attention_probs_dropout_prob\": config.attention_dropout,\n",
    "                \"output_hidden_states\": True,\n",
    "            }\n",
    "        )\n",
    "        hidden_size = self.model_config.hidden_size\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_path, config=self.model_config)\n",
    "\n",
    "        self.lstm_type = config.lstm_type\n",
    "        if config.lstm_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "        elif config.lstm_type == \"gru\":\n",
    "            self.lstm = nn.GRU(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "\n",
    "        self.pos_emb = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size * self.use_hidden_states),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "        head_input_size = hidden_size * self.use_hidden_states if config.lstm_type == \"none\" else hidden_size * 2\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(head_input_size, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(128, config.class_num),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * self.use_hidden_states)\n",
    "\n",
    "        self.head.apply(self._init_weights)\n",
    "        if config.lstm_type != \"none\":\n",
    "            self._lstm_init_weights(self.lstm)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    # Tensorflow/Keras-like initialization for GRU\n",
    "    def _lstm_init_weights(self, module):\n",
    "        for name, p in module.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            elif \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(p.data)\n",
    "            elif \"bias\" in name:\n",
    "                p.data.fill_(0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, positions):\n",
    "        x_pos = self.pos_emb(positions)\n",
    "        x_bb = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x_bb = torch.cat(x_bb.hidden_states[-self.use_hidden_states :], dim=-1)\n",
    "        x = x_bb + x_pos\n",
    "        x = self.layer_norm(x)\n",
    "        if self.lstm_type != \"none\":\n",
    "            x, _ = self.lstm(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]コマンドライン引数\n",
    "config_name = \"exp_087_train\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:14\u001b[0m | \u001b[1mINFO ] exp:087 start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(config_name, config_dir=Path(\"../config\"))\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f\"exp:{config.exp} start\")\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "config.debug = debug\n",
    "config.use_fold = 3\n",
    "config.eval_steps = 500  # 100\n",
    "config.ema_update_after_step = 100\n",
    "\n",
    "config.epochs = 2\n",
    "config.first_cycle_epochs = 2\n",
    "config.add_epochs = 2\n",
    "config.add_first_cycle_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:24\u001b[0m | \u001b[1mINFO ] Data Size: 13854\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dpr = DetectDataProvider(config, \"train\")\n",
    "data = dpr.load_data()\n",
    "logger.info(f\"Data Size: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [TODO]データサイズを調整する\n",
    "\n",
    "data_ = []\n",
    "for fold in [-1, 0, 1, 2]:\n",
    "    fold_data = [d for d in data if d[\"fold\"] == fold]\n",
    "    fold_data = fold_data[:100]\n",
    "    data_.extend(fold_data)\n",
    "\n",
    "data = data_\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_train_loaders(config, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self, config: DictConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.use_hidden_states = config.use_hidden_states\n",
    "        self.model_config = AutoConfig.from_pretrained(config.model_path)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": config.hidden_dropout,\n",
    "                \"attention_probs_dropout_prob\": config.attention_dropout,\n",
    "                \"output_hidden_states\": True,\n",
    "            }\n",
    "        )\n",
    "        hidden_size = self.model_config.hidden_size\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_path, config=self.model_config)\n",
    "\n",
    "        self.lstlm_type = config.lstm_type\n",
    "        if config.lstm_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "        elif config.lstm_type == \"gru\":\n",
    "            self.lstm = nn.GRU(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * self.use_hidden_states, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * self.use_hidden_states)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.head.apply(self._init_weights)\n",
    "\n",
    "    # DeBERTaの重み初期化関数\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = torch.cat(outputs.hidden_states[-self.use_hidden_states :], dim=-1)  # N層分のhidden_statesをconcat\n",
    "        if self.lstm_type != \"none\":\n",
    "            x, _ = self.lstm(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    # 指定した層の数だけ再初期化する(エンコーダーの最後の層からカウント)\n",
    "    def reinit_layers(self, reinit_layer_num: int):\n",
    "        for i in range(1, reinit_layer_num + 1):\n",
    "            self.backbone.encoder.layer[-i].apply(self._init_weights)\n",
    "\n",
    "    # 指定した層の数だけFreezeする(エンコーダーの最初の層からカウント)\n",
    "    def freeze_layers(self, freeze_layer_num: int):\n",
    "        for i in range(freeze_layer_num):\n",
    "            if i == 0:\n",
    "                for params in self.backbone.embeddings.parameters():\n",
    "                    params.requires_grad = False\n",
    "            else:\n",
    "                for params in self.backbone.encoder.layer[i - 1].parameters():\n",
    "                    params.requires_grad = False\n",
    "\n",
    "    # 初期化した層以外の層をFreezeする\n",
    "    def freeze_backbone(self, reinit_layer_num: int):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for i in range(1, reinit_layer_num + 1):\n",
    "            for params in self.backbone.encoder.layer[-i].parameters():\n",
    "                params.requires_grad = True\n",
    "\n",
    "    # BackboneのFreezeを解除する, 元からFreezeに指定した層はFreezeのまま\n",
    "    def unfreeze_backbone(self, freeze_layer_num: int):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.freeze_layers(freeze_layer_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:41\u001b[0m | \u001b[1mINFO ] FOLD0 : Training Start...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72cb1ecc004e6dae0b3f7a5d68c536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc93353a98344b682e6c8d0da8b1269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ee87bea114e4387ad7c836eae05b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:08:44\u001b[0m | \u001b[1mINFO ] Valid : Epoch=0, Loss=1.83803, Score=0.80858 Threshold=0.32499999999999996\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:08:46\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=0, Loss=2.55542, LR=1.00000e-06\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11aa3cade60490eb51f4b5f38f69d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5919c0e72a4729aba48c3fbe0864c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:12:41\u001b[0m | \u001b[1mINFO ] Valid : Epoch=1, Loss=4.20555, Score=0.84081 Threshold=0.27499999999999997\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:12:46\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=1, Loss=6.40125, LR=4.98946e-07\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:12:50\u001b[0m | \u001b[1mINFO ] FOLD0 : First Training Done! -->> Best Score: 0.8408107492598499, Best Steps: 1000\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n\u001b[1;32m     18\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create High-Quality Dataloader\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_loader\u001b[38;5;241m.\u001b[39mdataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "oof_dfs = []\n",
    "best_steps, best_add_steps = [], []\n",
    "collate_fn = CollateFn(get_tokenizer(config), is_train=True)\n",
    "\n",
    "# この学習でベストなステップ数とOOFに対する予測値を取ることが目的\n",
    "for fold, (train_loader, valid_loader) in enumerate(dataloaders):\n",
    "    logger.info(f\"FOLD{fold} : Training Start...\")\n",
    "\n",
    "    # First Training\n",
    "    trainer = Trainer(config, logger, save_suffix=f\"_fold{fold}\")\n",
    "    best_score, best_steps_, _ = trainer.train(train_loader, valid_loader)\n",
    "    if config.smooth_type == \"online\":\n",
    "        loss_soft_matrix = trainer.loss_fn.soft_matrix.clone()\n",
    "    best_steps.append(best_steps_)\n",
    "    logger.info(f\"FOLD{fold} : First Training Done! -->> Best Score: {best_score}, Best Steps: {best_steps_}\")\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Create High-Quality Dataloader\n",
    "    train_dataset = train_loader.dataset\n",
    "    train_dataset.drop_first_only_data()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=get_sampler(train_dataset),\n",
    "        batch_size=config.train_batch,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Additional Training\n",
    "    trainer = Trainer(config, logger, save_suffix=f\"_fold{fold}\")\n",
    "    if config.smooth_type == \"online\":\n",
    "        trainer.loss_fn.soft_matrix = loss_soft_matrix\n",
    "    best_score, best_add_steps_, oof_df = trainer.train(\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        retrain=True,\n",
    "        retrain_weight_name=f\"model_fold{fold}_best\",\n",
    "        retrain_best_score=best_score,\n",
    "    )\n",
    "    best_add_steps.append(best_add_steps_)\n",
    "    oof_df.write_parquet(config.output_path / f\"oof_fold{fold}.parquet\")\n",
    "    oof_dfs.append(oof_df)\n",
    "    logger.info(\n",
    "        f\"FOLD{fold} : Additional Training Done! -->> Best Score: {best_score}, Best Add Steps: {best_add_steps_}\"\n",
    "    )\n",
    "\n",
    "    del train_loader, valid_loader, train_dataset, trainer, oof_df\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "del dataloaders\n",
    "gc.collect()\n",
    "\n",
    "# Save OOF\n",
    "oof_df = pl.concat(oof_dfs)\n",
    "oof_df.write_parquet(config.output_path / \"oof.parquet\")\n",
    "del oof_dfs\n",
    "gc.collect()\n",
    "\n",
    "# Get Best Negative Threshold\n",
    "best_score, best_th = get_best_negative_threshold(config, oof_df)\n",
    "message = f\"Overall OOF Best Score: {best_score}, Best Negative Threshold: {best_th}\"\n",
    "logger.info(message)\n",
    "config.negative_th = best_th.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 07:50:35\u001b[0m | \u001b[1mINFO ] Full Train : Training Start...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a703d23b2438a8f2717e51ee795ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efecf7262854478a32cf19f2b8ae5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 07:51:08\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=0, Loss=3.26228, LR=1.00000e-06\u001b[0m\n",
      "[ \u001b[32m2024-10-21 07:51:08\u001b[0m | \u001b[1mINFO ] Full Train : First Training Done!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70051ed05a54492a191d7fc2f87644d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d1e9bfb1034b44a3a7c2a860b15313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.58 GiB total capacity; 23.20 GiB already allocated; 19.19 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39msmooth_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     30\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mloss_fn\u001b[38;5;241m.\u001b[39msoft_matrix \u001b[38;5;241m=\u001b[39m loss_soft_matrix\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain_weight_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_full\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_add_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Train : Additional Training Done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_loader, trainer\n",
      "Cell \u001b[0;32mIn[10], line 100\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader, retrain, retrain_weight_name, retrain_best_score, full_train, full_steps, eval_only)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_train_complete:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m _, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), n\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maccumulation_steps\n",
      "Cell \u001b[0;32mIn[10], line 202\u001b[0m, in \u001b[0;36mTrainer.forward_step\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    199\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m--> 202\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out, labels)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, loss\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/exp/../src/model/detect_model.py:76\u001b[0m, in \u001b[0;36mDetectModel.forward\u001b[0;34m(self, input_ids, attention_mask, positions)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, positions):\n\u001b[1;32m     75\u001b[0m     x_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(positions)\n\u001b[0;32m---> 76\u001b[0m     x_bb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     x_bb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_bb\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_hidden_states :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m     x \u001b[38;5;241m=\u001b[39m x_bb \u001b[38;5;241m+\u001b[39m x_pos\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1061\u001b[0m )\n\u001b[0;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    499\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         output_attentions,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:366\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    364\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n\u001b[1;32m    365\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 366\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (layer_output, att_matrix)\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:332\u001b[0m, in \u001b[0;36mDebertaV2Output.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m--> 332\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    334\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.58 GiB total capacity; 23.20 GiB already allocated; 19.19 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# # 全データ学習を行う\n",
    "if config.full_train:\n",
    "    full_steps = np.max(best_steps)\n",
    "    full_add_steps = np.max(best_add_steps)\n",
    "    logger.info(\"Full Train : Training Start...\")\n",
    "    train_loader = get_full_train_loader(config, data)\n",
    "\n",
    "    # First Training\n",
    "    trainer = Trainer(config, logger, save_suffix=\"\")\n",
    "    trainer.train(train_loader, valid_loader=None, full_train=True, full_steps=full_steps)\n",
    "    if config.smooth_type == \"online\":\n",
    "        loss_soft_matrix = trainer.loss_fn.soft_matrix.clone()\n",
    "    logger.info(\"Full Train : First Training Done!\")\n",
    "\n",
    "    # Create High-Quality Dataloader\n",
    "    train_dataset = train_loader.dataset\n",
    "    train_dataset.drop_first_only_data()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=get_sampler(train_dataset),\n",
    "        batch_size=config.train_batch,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Additional Training\n",
    "    trainer = Trainer(config, logger, save_suffix=\"\")\n",
    "    if config.smooth_type == \"online\":\n",
    "        trainer.loss_fn.soft_matrix = loss_soft_matrix\n",
    "    trainer.train(\n",
    "        train_loader,\n",
    "        valid_loader=None,\n",
    "        retrain=True,\n",
    "        retrain_weight_name=\"model_full\",\n",
    "        full_train=True,\n",
    "        full_steps=full_add_steps,\n",
    "    )\n",
    "    logger.info(\"Full Train : Additional Training Done!\")\n",
    "\n",
    "    del train_loader, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04906380169061845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check Prefix Validity: 100%|██████████| 300/300 [00:00<00:00, 843.14it/s]\n",
      "Check PII Validity: 100%|██████████| 155221/155221 [14:01<00:00, 184.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572628474337191\n"
     ]
    }
   ],
   "source": [
    "# [TODO] 後で編集する\n",
    "oof_df = pl.read_parquet(config.output_path / \"oof.parquet\")\n",
    "pred_df = get_pred_df(oof_df, config.class_num, negative_th=0.35)\n",
    "truth_df = get_truth_df(config, pred_df[\"document\"].unique().to_list(), convert_idx=True)\n",
    "score = evaluate_metric(pred_df, truth_df)\n",
    "print(score)\n",
    "\n",
    "pper = PostProcessor(config)\n",
    "pred_df = pper.post_process(pred_df)\n",
    "score = evaluate_metric(pred_df, truth_df)\n",
    "print(score)\n",
    "\n",
    "# logger.info(f\"Post Processed Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_df' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
