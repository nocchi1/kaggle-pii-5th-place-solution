{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../config/exp_118_train.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../config/exp_118_train.yaml\n",
    "exp: \"118\"\n",
    "first_exp: \"087\"\n",
    "run_type: \"train\"\n",
    "task_type: \"classify\"\n",
    "device: \"cuda\"\n",
    "seed: 10\n",
    "\n",
    "# data preprocess\n",
    "first_negative_th: 0.400  # [TODO]あとで調整\n",
    "n_fold: 3\n",
    "use_fold: 3\n",
    "\n",
    "# dataset, dataloader\n",
    "add_newline_token: true\n",
    "# max_length: 128\n",
    "# train_stride: 96\n",
    "# eval_stride: 64\n",
    "# train_batch: 16\n",
    "# eval_batch: 64\n",
    "\n",
    "# model\n",
    "model_path: \"microsoft/deberta-v3-large\"\n",
    "lstm_type: \"none\"\n",
    "use_hidden_states: 2\n",
    "dropout: 0.10\n",
    "hidden_dropout: 0.10\n",
    "attention_dropout: 0.10\n",
    "reinit_layer_num: 0\n",
    "freeze_layer_num: 0\n",
    "\n",
    "# loss\n",
    "positive_class_weight: 10\n",
    "\n",
    "# optimizer\n",
    "optimizer_type: \"AdamW\"\n",
    "pretrained_lr: 1e-6\n",
    "head_lr: 1e-4\n",
    "weight_decay: 0.01\n",
    "betas: [0.9, 0.999]\n",
    "\n",
    "# scheduler\n",
    "scheduler_type: \"cosine_custom\"\n",
    "first_cycle_epochs: 4\n",
    "cycle_factor: 1\n",
    "num_warmup_steps: 0\n",
    "min_lr: 1e-9\n",
    "gamma: 1.0\n",
    "\n",
    "# # training\n",
    "# epochs: 4\n",
    "# accumulation_steps: 2\n",
    "# eval_steps: 1000\n",
    "# negative_th: 0.660\n",
    "# negative_th_method: \"overall\"\n",
    "# amp: true\n",
    "# ema: true\n",
    "# ema_decay: 0.999\n",
    "# ema_update_after_step: 8000\n",
    "\n",
    "# full training\n",
    "full_train: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.postprocess import PostProcessor\n",
    "from src.preprocess import DetectDataProvider\n",
    "from src.train import Trainer, get_full_train_loader, get_train_loaders\n",
    "from src.train.dataloader_utils import CollateFn, get_sampler, get_tokenizer\n",
    "from src.utils import TimeUtil, get_config, get_logger, seed_everything\n",
    "from src.utils.metric import get_best_negative_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd-stageの目的は, 1st-stageでのNAME-STUDENTのFPを現象させること\n",
    "# 後処理は2nd-stageの前では行わずに, 2nd-stageの後で行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]コマンドライン引数\n",
    "config_name = \"exp_118_train\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 11:26:23\u001b[0m | \u001b[1mINFO ] exp:118 start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(config_name, config_dir=Path(\"../config\"))\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f\"exp:{config.exp} start\")\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Notebookの時はPathを変更する\n",
    "config.input_path = Path(\"../data/input\")\n",
    "config.exter_path = Path(\"../data/input/external\")\n",
    "config.output_path = Path(\"../data/output\") / config.exp\n",
    "config.output_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# コンペデータの読み込み\n",
    "train_data = load_json_data(config.input_path / \"train.json\", debug=config.debug)\n",
    "train_data = convert_label_str2index(train_data, remove_prefix=False)\n",
    "\n",
    "# 1st stageで得られたoof_dfに対して予測を行う\n",
    "oof_df = pl.read_parquet(config.output_path.parent / config.first_exp / \"oof.parquet\")\n",
    "class_num = len(list(filter(lambda x: \"pred\" in x, oof_df.columns)))\n",
    "pred_df = get_pred_df(oof_df, class_num=class_num, negative_th=th)\n",
    "if class_num == 8:\n",
    "    pred_df = restore_prefix(config, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 実際に実行する際のコード\n",
    "\n",
    "\n",
    "# # load 2nd stage data\n",
    "# train_data = load_2nd_stage_data(train_data, pred_df, is_train=True)\n",
    "# if config.debug:\n",
    "#     train_data = train_data[:300]\n",
    "\n",
    "# # get cv fold\n",
    "# fold_array = get_cv_fold_2nd(train_data, n_splits=config.n_fold, seed=config.seed)\n",
    "\n",
    "# # get dataloader\n",
    "# dataloaders = get_train_loaders_2nd(config, train_data, fold_array, use_fold=config.use_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyDataLoader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_2nd_stage_data(\n",
    "    org_data: List[dict], pred_df: pl.DataFrame, is_train: bool = True, use_fn_label: bool = False\n",
    ") -> List[dict]:\n",
    "    # トークンのインデックスに整合性を持たせる処理が必要\n",
    "    token_index_df = []\n",
    "    for data in org_data:\n",
    "        token_index_df.append(\n",
    "            pl.DataFrame(\n",
    "                {\n",
    "                    \"document\": [data[\"document\"]] * len(data[\"tokens\"]),\n",
    "                    \"token_index\": list(range(len(data[\"tokens\"]))),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    token_index_df = pl.concat(token_index_df)\n",
    "\n",
    "    # 予測のないトークンに予測値を0にする\n",
    "    pred_ids = pred_df[\"document\"].unique().to_list()\n",
    "    token_index_df = token_index_df.filter(pl.col(\"document\").is_in(pred_ids))\n",
    "    pred_df = token_index_df.join(pred_df, on=[\"document\", \"token_index\"], how=\"left\")\n",
    "    pred_df = pred_df.with_columns(\n",
    "        name_pred=pl.col(\"pred\").replace(\n",
    "            {1: 1, 8: 1}, default=0\n",
    "        )  # 1st_stage -> with prefix, 2nd_stage -> without prefix\n",
    "    )\n",
    "    pred_df = pred_df.sort(\"document\", \"token_index\")\n",
    "    name_pred_dict = {doc_id: tmp_df[\"name_pred\"].to_list() for doc_id, tmp_df in pred_df.group_by(\"document\")}\n",
    "\n",
    "    # 元のデータセットにNAME_STUDENTの予測値を結合する\n",
    "    merged_data = []\n",
    "    for data in org_data:\n",
    "        doc_id = data[\"document\"]\n",
    "        # pred_dfに含まれないデータは含めない\n",
    "        if doc_id not in name_pred_dict:\n",
    "            continue\n",
    "        name_preds = name_pred_dict[doc_id]\n",
    "        data[\"name_preds\"] = name_preds\n",
    "\n",
    "        # 2nd stageで使用するラベルを作成する\n",
    "        if is_train:\n",
    "            second_labels, name_preds_ow = [], []\n",
    "            for org_label, name_pred in zip(data[\"labels\"], name_preds):\n",
    "                if name_pred == 1 and org_label in [1, 8]:\n",
    "                    second_labels.append(1)\n",
    "                    name_preds_ow.append(1)\n",
    "                elif name_pred == 1 and org_label not in [1, 8]:\n",
    "                    second_labels.append(0)\n",
    "                    name_preds_ow.append(1)\n",
    "                # FNも学習対象とするとき\n",
    "                elif use_fn_label and name_pred == 0 and org_label in [1, 8]:\n",
    "                    second_labels.append(1)\n",
    "                    name_preds_ow.append(1)\n",
    "                else:\n",
    "                    second_labels.append(-1)\n",
    "                    name_preds_ow.append(0)\n",
    "\n",
    "            data[\"second_labels\"] = second_labels\n",
    "            data[\"name_preds\"] = name_preds_ow\n",
    "\n",
    "        # 学習するトークンがない場合はあらかじめ除外\n",
    "        trainable_num = sum(data[\"name_preds\"])\n",
    "        if trainable_num == 0:\n",
    "            continue\n",
    "        merged_data.append(data)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_fold_2nd(data: List[dict], n_splits: int, seed: int = 10) -> np.ndarray:\n",
    "    stratify_list = []\n",
    "    for d in data:\n",
    "        second_label = [label for label in d[\"second_labels\"] if label != -1]\n",
    "        if len(set(second_label)) == 2:\n",
    "            stratify_list.append(2)  # 2 when both 1 and 0 are included\n",
    "        else:\n",
    "            stratify_list.append(second_label[0])  # 1 or 0\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    folds = np.ones(len(data)) * -1\n",
    "    for fold, (_, valid_idx) in enumerate(skf.split(data, y=stratify_list)):\n",
    "        folds[valid_idx] = fold\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    import torch\n",
    "\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "\n",
    "class DetectModel(nn.Module):\n",
    "    def __init__(self, config: DictConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.use_hidden_states = config.use_hidden_states\n",
    "        self.model_config = AutoConfig.from_pretrained(config.model_path)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": config.hidden_dropout,\n",
    "                \"attention_probs_dropout_prob\": config.attention_dropout,\n",
    "                \"output_hidden_states\": True,\n",
    "            }\n",
    "        )\n",
    "        hidden_size = self.model_config.hidden_size\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_path, config=self.model_config)\n",
    "\n",
    "        self.lstm_type = config.lstm_type\n",
    "        if config.lstm_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "        elif config.lstm_type == \"gru\":\n",
    "            self.lstm = nn.GRU(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "\n",
    "        self.pos_emb = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size * self.use_hidden_states),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "        head_input_size = hidden_size * self.use_hidden_states if config.lstm_type == \"none\" else hidden_size * 2\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(head_input_size, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(128, config.class_num),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * self.use_hidden_states)\n",
    "\n",
    "        self.head.apply(self._init_weights)\n",
    "        if config.lstm_type != \"none\":\n",
    "            self._lstm_init_weights(self.lstm)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    # Tensorflow/Keras-like initialization for GRU\n",
    "    def _lstm_init_weights(self, module):\n",
    "        for name, p in module.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            elif \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(p.data)\n",
    "            elif \"bias\" in name:\n",
    "                p.data.fill_(0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, positions):\n",
    "        x_pos = self.pos_emb(positions)\n",
    "        x_bb = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x_bb = torch.cat(x_bb.hidden_states[-self.use_hidden_states :], dim=-1)\n",
    "        x = x_bb + x_pos\n",
    "        x = self.layer_norm(x)\n",
    "        if self.lstm_type != \"none\":\n",
    "            x, _ = self.lstm(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]コマンドライン引数\n",
    "config_name = \"exp_087_train\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:14\u001b[0m | \u001b[1mINFO ] exp:087 start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = get_config(config_name, config_dir=Path(\"../config\"))\n",
    "logger = get_logger(config.output_path)\n",
    "logger.info(f\"exp:{config.exp} start\")\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "config.debug = debug\n",
    "config.use_fold = 3\n",
    "config.eval_steps = 500  # 100\n",
    "config.ema_update_after_step = 100\n",
    "\n",
    "config.epochs = 2\n",
    "config.first_cycle_epochs = 2\n",
    "config.add_epochs = 2\n",
    "config.add_first_cycle_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:24\u001b[0m | \u001b[1mINFO ] Data Size: 13854\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dpr = DetectDataProvider(config, \"train\")\n",
    "data = dpr.load_data()\n",
    "logger.info(f\"Data Size: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [TODO]データサイズを調整する\n",
    "\n",
    "data_ = []\n",
    "for fold in [-1, 0, 1, 2]:\n",
    "    fold_data = [d for d in data if d[\"fold\"] == fold]\n",
    "    fold_data = fold_data[:100]\n",
    "    data_.extend(fold_data)\n",
    "\n",
    "data = data_\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_train_loaders(config, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self, config: DictConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.use_hidden_states = config.use_hidden_states\n",
    "        self.model_config = AutoConfig.from_pretrained(config.model_path)\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"hidden_dropout_prob\": config.hidden_dropout,\n",
    "                \"attention_probs_dropout_prob\": config.attention_dropout,\n",
    "                \"output_hidden_states\": True,\n",
    "            }\n",
    "        )\n",
    "        hidden_size = self.model_config.hidden_size\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_path, config=self.model_config)\n",
    "\n",
    "        self.lstlm_type = config.lstm_type\n",
    "        if config.lstm_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "        elif config.lstm_type == \"gru\":\n",
    "            self.lstm = nn.GRU(\n",
    "                hidden_size * self.use_hidden_states, hidden_size, num_layers=1, batch_first=True, bidirectional=True\n",
    "            )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * self.use_hidden_states, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * self.use_hidden_states)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.head.apply(self._init_weights)\n",
    "\n",
    "    # DeBERTaの重み初期化関数\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = torch.cat(outputs.hidden_states[-self.use_hidden_states :], dim=-1)  # N層分のhidden_statesをconcat\n",
    "        if self.lstm_type != \"none\":\n",
    "            x, _ = self.lstm(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    # 指定した層の数だけ再初期化する(エンコーダーの最後の層からカウント)\n",
    "    def reinit_layers(self, reinit_layer_num: int):\n",
    "        for i in range(1, reinit_layer_num + 1):\n",
    "            self.backbone.encoder.layer[-i].apply(self._init_weights)\n",
    "\n",
    "    # 指定した層の数だけFreezeする(エンコーダーの最初の層からカウント)\n",
    "    def freeze_layers(self, freeze_layer_num: int):\n",
    "        for i in range(freeze_layer_num):\n",
    "            if i == 0:\n",
    "                for params in self.backbone.embeddings.parameters():\n",
    "                    params.requires_grad = False\n",
    "            else:\n",
    "                for params in self.backbone.encoder.layer[i - 1].parameters():\n",
    "                    params.requires_grad = False\n",
    "\n",
    "    # 初期化した層以外の層をFreezeする\n",
    "    def freeze_backbone(self, reinit_layer_num: int):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for i in range(1, reinit_layer_num + 1):\n",
    "            for params in self.backbone.encoder.layer[-i].parameters():\n",
    "                params.requires_grad = True\n",
    "\n",
    "    # BackboneのFreezeを解除する, 元からFreezeに指定した層はFreezeのまま\n",
    "    def unfreeze_backbone(self, freeze_layer_num: int):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.freeze_layers(freeze_layer_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:05:41\u001b[0m | \u001b[1mINFO ] FOLD0 : Training Start...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72cb1ecc004e6dae0b3f7a5d68c536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc93353a98344b682e6c8d0da8b1269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ee87bea114e4387ad7c836eae05b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:08:44\u001b[0m | \u001b[1mINFO ] Valid : Epoch=0, Loss=1.83803, Score=0.80858 Threshold=0.32499999999999996\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:08:46\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=0, Loss=2.55542, LR=1.00000e-06\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11aa3cade60490eb51f4b5f38f69d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5919c0e72a4729aba48c3fbe0864c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 08:12:41\u001b[0m | \u001b[1mINFO ] Valid : Epoch=1, Loss=4.20555, Score=0.84081 Threshold=0.27499999999999997\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:12:46\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=1, Loss=6.40125, LR=4.98946e-07\u001b[0m\n",
      "[ \u001b[32m2024-10-21 08:12:50\u001b[0m | \u001b[1mINFO ] FOLD0 : First Training Done! -->> Best Score: 0.8408107492598499, Best Steps: 1000\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n\u001b[1;32m     18\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create High-Quality Dataloader\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_loader\u001b[38;5;241m.\u001b[39mdataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "oof_dfs = []\n",
    "best_steps, best_add_steps = [], []\n",
    "collate_fn = CollateFn(get_tokenizer(config), is_train=True)\n",
    "\n",
    "# この学習でベストなステップ数とOOFに対する予測値を取ることが目的\n",
    "for fold, (train_loader, valid_loader) in enumerate(dataloaders):\n",
    "    logger.info(f\"FOLD{fold} : Training Start...\")\n",
    "\n",
    "    # First Training\n",
    "    trainer = Trainer(config, logger, save_suffix=f\"_fold{fold}\")\n",
    "    best_score, best_steps_, _ = trainer.train(train_loader, valid_loader)\n",
    "    if config.smooth_type == \"online\":\n",
    "        loss_soft_matrix = trainer.loss_fn.soft_matrix.clone()\n",
    "    best_steps.append(best_steps_)\n",
    "    logger.info(f\"FOLD{fold} : First Training Done! -->> Best Score: {best_score}, Best Steps: {best_steps_}\")\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Create High-Quality Dataloader\n",
    "    train_dataset = train_loader.dataset\n",
    "    train_dataset.drop_first_only_data()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=get_sampler(train_dataset),\n",
    "        batch_size=config.train_batch,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Additional Training\n",
    "    trainer = Trainer(config, logger, save_suffix=f\"_fold{fold}\")\n",
    "    if config.smooth_type == \"online\":\n",
    "        trainer.loss_fn.soft_matrix = loss_soft_matrix\n",
    "    best_score, best_add_steps_, oof_df = trainer.train(\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        retrain=True,\n",
    "        retrain_weight_name=f\"model_fold{fold}_best\",\n",
    "        retrain_best_score=best_score,\n",
    "    )\n",
    "    best_add_steps.append(best_add_steps_)\n",
    "    oof_df.write_parquet(config.output_path / f\"oof_fold{fold}.parquet\")\n",
    "    oof_dfs.append(oof_df)\n",
    "    logger.info(\n",
    "        f\"FOLD{fold} : Additional Training Done! -->> Best Score: {best_score}, Best Add Steps: {best_add_steps_}\"\n",
    "    )\n",
    "\n",
    "    del train_loader, valid_loader, train_dataset, trainer, oof_df\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "del dataloaders\n",
    "gc.collect()\n",
    "\n",
    "# Save OOF\n",
    "oof_df = pl.concat(oof_dfs)\n",
    "oof_df.write_parquet(config.output_path / \"oof.parquet\")\n",
    "del oof_dfs\n",
    "gc.collect()\n",
    "\n",
    "# Get Best Negative Threshold\n",
    "best_score, best_th = get_best_negative_threshold(config, oof_df)\n",
    "message = f\"Overall OOF Best Score: {best_score}, Best Negative Threshold: {best_th}\"\n",
    "logger.info(message)\n",
    "config.negative_th = best_th.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 07:50:35\u001b[0m | \u001b[1mINFO ] Full Train : Training Start...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a703d23b2438a8f2717e51ee795ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efecf7262854478a32cf19f2b8ae5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m2024-10-21 07:51:08\u001b[0m | \u001b[1mINFO ] [Train] : Epoch=0, Loss=3.26228, LR=1.00000e-06\u001b[0m\n",
      "[ \u001b[32m2024-10-21 07:51:08\u001b[0m | \u001b[1mINFO ] Full Train : First Training Done!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70051ed05a54492a191d7fc2f87644d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d1e9bfb1034b44a3a7c2a860b15313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.58 GiB total capacity; 23.20 GiB already allocated; 19.19 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39msmooth_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     30\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mloss_fn\u001b[38;5;241m.\u001b[39msoft_matrix \u001b[38;5;241m=\u001b[39m loss_soft_matrix\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrain_weight_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_full\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_add_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Train : Additional Training Done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_loader, trainer\n",
      "Cell \u001b[0;32mIn[10], line 100\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader, retrain, retrain_weight_name, retrain_best_score, full_train, full_steps, eval_only)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_train_complete:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m _, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), n\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maccumulation_steps\n",
      "Cell \u001b[0;32mIn[10], line 202\u001b[0m, in \u001b[0;36mTrainer.forward_step\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    199\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m--> 202\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out, labels)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, loss\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/exp/../src/model/detect_model.py:76\u001b[0m, in \u001b[0;36mDetectModel.forward\u001b[0;34m(self, input_ids, attention_mask, positions)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, positions):\n\u001b[1;32m     75\u001b[0m     x_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(positions)\n\u001b[0;32m---> 76\u001b[0m     x_bb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     x_bb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_bb\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_hidden_states :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m     x \u001b[38;5;241m=\u001b[39m x_bb \u001b[38;5;241m+\u001b[39m x_pos\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1061\u001b[0m )\n\u001b[0;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    499\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         output_attentions,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:366\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    364\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n\u001b[1;32m    365\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 366\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (layer_output, att_matrix)\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:332\u001b[0m, in \u001b[0;36mDebertaV2Output.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m--> 332\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    334\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/kaggle-pii-5th-place-solution/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.58 GiB total capacity; 23.20 GiB already allocated; 19.19 MiB free; 23.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# # 全データ学習を行う\n",
    "if config.full_train:\n",
    "    full_steps = np.max(best_steps)\n",
    "    full_add_steps = np.max(best_add_steps)\n",
    "    logger.info(\"Full Train : Training Start...\")\n",
    "    train_loader = get_full_train_loader(config, data)\n",
    "\n",
    "    # First Training\n",
    "    trainer = Trainer(config, logger, save_suffix=\"\")\n",
    "    trainer.train(train_loader, valid_loader=None, full_train=True, full_steps=full_steps)\n",
    "    if config.smooth_type == \"online\":\n",
    "        loss_soft_matrix = trainer.loss_fn.soft_matrix.clone()\n",
    "    logger.info(\"Full Train : First Training Done!\")\n",
    "\n",
    "    # Create High-Quality Dataloader\n",
    "    train_dataset = train_loader.dataset\n",
    "    train_dataset.drop_first_only_data()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=get_sampler(train_dataset),\n",
    "        batch_size=config.train_batch,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Additional Training\n",
    "    trainer = Trainer(config, logger, save_suffix=\"\")\n",
    "    if config.smooth_type == \"online\":\n",
    "        trainer.loss_fn.soft_matrix = loss_soft_matrix\n",
    "    trainer.train(\n",
    "        train_loader,\n",
    "        valid_loader=None,\n",
    "        retrain=True,\n",
    "        retrain_weight_name=\"model_full\",\n",
    "        full_train=True,\n",
    "        full_steps=full_add_steps,\n",
    "    )\n",
    "    logger.info(\"Full Train : Additional Training Done!\")\n",
    "\n",
    "    del train_loader, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04906380169061845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check Prefix Validity: 100%|██████████| 300/300 [00:00<00:00, 843.14it/s]\n",
      "Check PII Validity: 100%|██████████| 155221/155221 [14:01<00:00, 184.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572628474337191\n"
     ]
    }
   ],
   "source": [
    "# [TODO] 後で編集する\n",
    "oof_df = pl.read_parquet(config.output_path / \"oof.parquet\")\n",
    "pred_df = get_pred_df(oof_df, config.class_num, negative_th=0.35)\n",
    "truth_df = get_truth_df(config, pred_df[\"document\"].unique().to_list(), convert_idx=True)\n",
    "score = evaluate_metric(pred_df, truth_df)\n",
    "print(score)\n",
    "\n",
    "pper = PostProcessor(config)\n",
    "pred_df = pper.post_process(pred_df)\n",
    "score = evaluate_metric(pred_df, truth_df)\n",
    "print(score)\n",
    "\n",
    "# logger.info(f\"Post Processed Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_df' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
